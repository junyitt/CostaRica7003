{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My colors are set!\n",
      "sklearn imported!\n",
      "lightgbm imported!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "mycols = [\"#66c2ff\", \"#5cd6d6\", \"#00cc99\", \"#85e085\", \"#ffd966\", \"#ffb366\", \"#ffb3b3\", \"#dab3ff\", \"#c2c2d6\"]\n",
    "sns.set_palette(palette = mycols, n_colors = 4)\n",
    "print('My colors are set!')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('sklearn imported!')\n",
    "\n",
    "import lightgbm as lgb\n",
    "print('lightgbm imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set has 9557 rows, and 143 features\n",
      "test set has 23856 rows, and 142 features\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv('./data/train.csv')\n",
    "test_set = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\n",
    "print(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.627394\n",
       "2    0.167103\n",
       "3    0.126504\n",
       "1    0.079000\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train_set['Target']\n",
    "target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier in test set which rez_esc is 99.0\n",
    "test_set.loc[test_set['rez_esc'] == 99.0 , 'rez_esc'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 5 rows which have missing value in train set \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rez_esc</th>\n",
       "      <td>82.954902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v18q1</th>\n",
       "      <td>76.823271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>71.779847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQBmeaned</th>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count\n",
       "rez_esc    82.954902\n",
       "v18q1      76.823271\n",
       "v2a1       71.779847\n",
       "SQBmeaned   0.052318\n",
       "meaneduc    0.052318\n",
       "Id          0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_na = train_set.isnull().sum().values / train_set.shape[0] *100\n",
    "df_na = pd.DataFrame(data_na, index=train_set.columns, columns=['Count'])\n",
    "df_na = df_na.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "missing_value_count = df_na[df_na['Count']>0].shape[0]\n",
    "\n",
    "print(f'We got {missing_value_count} rows which have missing value in train set ')\n",
    "df_na.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 5 rows which have missing value in test set \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rez_esc</th>\n",
       "      <td>82.381791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v18q1</th>\n",
       "      <td>75.980885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>72.950201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>0.129946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQBmeaned</th>\n",
       "      <td>0.129946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Count\n",
       "rez_esc     82.381791\n",
       "v18q1       75.980885\n",
       "v2a1        72.950201\n",
       "meaneduc     0.129946\n",
       "SQBmeaned    0.129946\n",
       "instlevel1   0.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_na = test_set.isnull().sum().values / test_set.shape[0] *100\n",
    "df_na = pd.DataFrame(data_na, index=test_set.columns, columns=['Count'])\n",
    "df_na = df_na.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "missing_value_count = df_na[df_na['Count']>0].shape[0]\n",
    "\n",
    "print(f'We got {missing_value_count} rows which have missing value in test set ')\n",
    "df_na.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill na\n",
    "def repalce_v18q1(x):\n",
    "    if x['v18q'] == 0:\n",
    "        return x['v18q']\n",
    "    else:\n",
    "        return x['v18q1']\n",
    "\n",
    "train_set['v18q1'] = train_set.apply(lambda x : repalce_v18q1(x),axis=1)\n",
    "test_set['v18q1'] = test_set.apply(lambda x : repalce_v18q1(x),axis=1)\n",
    "\n",
    "train_set['v2a1'] = train_set['v2a1'].fillna(value=train_set['tipovivi3'])\n",
    "test_set['v2a1'] = test_set['v2a1'].fillna(value=test_set['tipovivi3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['edjefe', 'edjefa']\n",
    "train_set[cols] = train_set[cols].replace({'no': 0, 'yes':1}).astype(float)\n",
    "test_set[cols] = test_set[cols].replace({'no': 0, 'yes':1}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['roof_waste_material'] = np.nan\n",
    "test_set['roof_waste_material'] = np.nan\n",
    "train_set['electricity_other'] = np.nan\n",
    "test_set['electricity_other'] = np.nan\n",
    "\n",
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_set['roof_waste_material'] = train_set.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "test_set['roof_waste_material'] = test_set.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "train_set['electricity_other'] = train_set.apply(lambda x : fill_no_electricity(x),axis=1)\n",
    "test_set['electricity_other'] = test_set.apply(lambda x : fill_no_electricity(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_is_adult(x):\n",
    "    if x['age'] <= 18:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "train_set['head<18'] = train_set.apply(lambda x : owner_is_adult(x),axis=1)\n",
    "test_set['head<18'] = test_set.apply(lambda x : owner_is_adult(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['adult'] = train_set['hogar_adul'] - train_set['hogar_mayor']\n",
    "train_set['dependency_count'] = train_set['hogar_nin'] + train_set['hogar_mayor']\n",
    "train_set['dependency'] = train_set['dependency_count'] / train_set['adult']\n",
    "train_set['child_percent'] = train_set['hogar_nin']/train_set['hogar_total']\n",
    "train_set['elder_percent'] = train_set['hogar_mayor']/train_set['hogar_total']\n",
    "train_set['adult_percent'] = train_set['hogar_adul']/train_set['hogar_total']\n",
    "test_set['adult'] = test_set['hogar_adul'] - test_set['hogar_mayor']\n",
    "test_set['dependency_count'] = test_set['hogar_nin'] + test_set['hogar_mayor']\n",
    "test_set['dependency'] = test_set['dependency_count'] / test_set['adult']\n",
    "test_set['child_percent'] = test_set['hogar_nin']/test_set['hogar_total']\n",
    "test_set['elder_percent'] = test_set['hogar_mayor']/test_set['hogar_total']\n",
    "test_set['adult_percent'] = test_set['hogar_adul']/test_set['hogar_total']\n",
    "\n",
    "train_set['rent_per_adult'] = train_set['v2a1']/train_set['hogar_adul']\n",
    "train_set['rent_per_person'] = train_set['v2a1']/train_set['hhsize']\n",
    "test_set['rent_per_adult'] = test_set['v2a1']/test_set['hogar_adul']\n",
    "test_set['rent_per_person'] = test_set['v2a1']/test_set['hhsize']\n",
    "\n",
    "train_set['overcrowding_room_and_bedroom'] = (train_set['hacdor'] + train_set['hacapo'])/2\n",
    "test_set['overcrowding_room_and_bedroom'] = (test_set['hacdor'] + test_set['hacapo'])/2\n",
    "\n",
    "train_set['no_appliances'] = train_set['refrig'] + train_set['computer'] + train_set['television']\n",
    "test_set['no_appliances'] = test_set['refrig'] + test_set['computer'] + test_set['television']\n",
    "\n",
    "train_set['r4h1_percent_in_male'] = train_set['r4h1'] / train_set['r4h3']\n",
    "train_set['r4m1_percent_in_female'] = train_set['r4m1'] / train_set['r4m3']\n",
    "train_set['r4h1_percent_in_total'] = train_set['r4h1'] / train_set['hhsize']\n",
    "train_set['r4m1_percent_in_total'] = train_set['r4m1'] / train_set['hhsize']\n",
    "train_set['r4t1_percent_in_total'] = train_set['r4t1'] / train_set['hhsize']\n",
    "test_set['r4h1_percent_in_male'] = test_set['r4h1'] / test_set['r4h3']\n",
    "test_set['r4m1_percent_in_female'] = test_set['r4m1'] / test_set['r4m3']\n",
    "test_set['r4h1_percent_in_total'] = test_set['r4h1'] / test_set['hhsize']\n",
    "test_set['r4m1_percent_in_total'] = test_set['r4m1'] / test_set['hhsize']\n",
    "test_set['r4t1_percent_in_total'] = test_set['r4t1'] / test_set['hhsize']\n",
    "\n",
    "train_set['rent_per_room'] = train_set['v2a1']/train_set['rooms']\n",
    "train_set['bedroom_per_room'] = train_set['bedrooms']/train_set['rooms']\n",
    "train_set['elder_per_room'] = train_set['hogar_mayor']/train_set['rooms']\n",
    "train_set['adults_per_room'] = train_set['adult']/train_set['rooms']\n",
    "train_set['child_per_room'] = train_set['hogar_nin']/train_set['rooms']\n",
    "train_set['male_per_room'] = train_set['r4h3']/train_set['rooms']\n",
    "train_set['female_per_room'] = train_set['r4m3']/train_set['rooms']\n",
    "train_set['room_per_person_household'] = train_set['hhsize']/train_set['rooms']\n",
    "\n",
    "test_set['rent_per_room'] = test_set['v2a1']/test_set['rooms']\n",
    "test_set['bedroom_per_room'] = test_set['bedrooms']/test_set['rooms']\n",
    "test_set['elder_per_room'] = test_set['hogar_mayor']/test_set['rooms']\n",
    "test_set['adults_per_room'] = test_set['adult']/test_set['rooms']\n",
    "test_set['child_per_room'] = test_set['hogar_nin']/test_set['rooms']\n",
    "test_set['male_per_room'] = test_set['r4h3']/test_set['rooms']\n",
    "test_set['female_per_room'] = test_set['r4m3']/test_set['rooms']\n",
    "test_set['room_per_person_household'] = test_set['hhsize']/test_set['rooms']\n",
    "\n",
    "train_set['rent_per_bedroom'] = train_set['v2a1']/train_set['bedrooms']\n",
    "train_set['edler_per_bedroom'] = train_set['hogar_mayor']/train_set['bedrooms']\n",
    "train_set['adults_per_bedroom'] = train_set['adult']/train_set['bedrooms']\n",
    "train_set['child_per_bedroom'] = train_set['hogar_nin']/train_set['bedrooms']\n",
    "train_set['male_per_bedroom'] = train_set['r4h3']/train_set['bedrooms']\n",
    "train_set['female_per_bedroom'] = train_set['r4m3']/train_set['bedrooms']\n",
    "train_set['bedrooms_per_person_household'] = train_set['hhsize']/train_set['bedrooms']\n",
    "\n",
    "test_set['rent_per_bedroom'] = test_set['v2a1']/test_set['bedrooms']\n",
    "test_set['edler_per_bedroom'] = test_set['hogar_mayor']/test_set['bedrooms']\n",
    "test_set['adults_per_bedroom'] = test_set['adult']/test_set['bedrooms']\n",
    "test_set['child_per_bedroom'] = test_set['hogar_nin']/test_set['bedrooms']\n",
    "test_set['male_per_bedroom'] = test_set['r4h3']/test_set['bedrooms']\n",
    "test_set['female_per_bedroom'] = test_set['r4m3']/test_set['bedrooms']\n",
    "test_set['bedrooms_per_person_household'] = test_set['hhsize']/test_set['bedrooms']\n",
    "\n",
    "train_set['tablet_per_person_household'] = train_set['v18q1']/train_set['hhsize']\n",
    "train_set['phone_per_person_household'] = train_set['qmobilephone']/train_set['hhsize']\n",
    "test_set['tablet_per_person_household'] = test_set['v18q1']/test_set['hhsize']\n",
    "test_set['phone_per_person_household'] = test_set['qmobilephone']/test_set['hhsize']\n",
    "\n",
    "train_set['age_12_19'] = train_set['hogar_nin'] - train_set['r4t1']\n",
    "test_set['age_12_19'] = test_set['hogar_nin'] - test_set['r4t1']    \n",
    "\n",
    "train_set['escolari_age'] = train_set['escolari']/train_set['age']\n",
    "test_set['escolari_age'] = test_set['escolari']/test_set['age']\n",
    "\n",
    "train_set['rez_esc_escolari'] = train_set['rez_esc']/train_set['escolari']\n",
    "train_set['rez_esc_r4t1'] = train_set['rez_esc']/train_set['r4t1']\n",
    "train_set['rez_esc_r4t2'] = train_set['rez_esc']/train_set['r4t2']\n",
    "train_set['rez_esc_r4t3'] = train_set['rez_esc']/train_set['r4t3']\n",
    "train_set['rez_esc_age'] = train_set['rez_esc']/train_set['age']\n",
    "test_set['rez_esc_escolari'] = test_set['rez_esc']/test_set['escolari']\n",
    "test_set['rez_esc_r4t1'] = test_set['rez_esc']/test_set['r4t1']\n",
    "test_set['rez_esc_r4t2'] = test_set['rez_esc']/test_set['r4t2']\n",
    "test_set['rez_esc_r4t3'] = test_set['rez_esc']/test_set['r4t3']\n",
    "test_set['rez_esc_age'] = test_set['rez_esc']/test_set['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set has 9557 rows, and 184 features\n",
      "test set has 23856 rows, and 183 features\n"
     ]
    }
   ],
   "source": [
    "train_set['dependency'] = train_set['dependency'].replace({np.inf: 0})\n",
    "test_set['dependency'] = test_set['dependency'].replace({np.inf: 0})\n",
    "\n",
    "print(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\n",
    "print(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 46 features\n",
      "new aggregate test set has 7352 rows, and 46 features\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "aggr_mean_list = ['rez_esc', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco2',\n",
    "             'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12',\n",
    "             'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',]\n",
    "\n",
    "other_list = ['escolari', 'age', 'escolari_age']\n",
    "\n",
    "for item in aggr_mean_list:\n",
    "    group_train_mean = train_set[item].groupby(train_set['idhogar']).mean()\n",
    "    group_test_mean = test_set[item].groupby(test_set['idhogar']).mean()\n",
    "    new_col = item + '_aggr_mean'\n",
    "    df_train[new_col] = group_train_mean\n",
    "    df_test[new_col] = group_test_mean\n",
    "\n",
    "for item in other_list:\n",
    "    for function in ['mean','std','min','max','sum']:\n",
    "        group_train = train_set[item].groupby(train_set['idhogar']).agg(function)\n",
    "        group_test = test_set[item].groupby(test_set['idhogar']).agg(function)\n",
    "        new_col = item + '_' + function\n",
    "        df_train[new_col] = group_train\n",
    "        df_test[new_col] = group_test\n",
    "\n",
    "print(f'new aggregate train set has {df_train.shape[0]} rows, and {df_train.shape[1]} features')\n",
    "print(f'new aggregate test set has {df_test.shape[0]} rows, and {df_test.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new train set has 9557 rows, and 230 features\n",
      "new test set has 23856 rows, and 229 features\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(train_set, df_train, on='idhogar')\n",
    "test = pd.merge(test_set, df_test, on='idhogar')\n",
    "\n",
    "#fill all na as 0\n",
    "train_agg.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "print(f'new train set has {train_agg.shape[0]} rows, and {train_agg.shape[1]} features')\n",
    "print(f'new test set has {test.shape[0]} rows, and {test.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to data descriptions,ONLY the heads of household are used in scoring. /\n",
    "#All household members are included in test + the sample submission, but only heads of households are scored.\n",
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jy\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 positive feature: \n",
      "Target                  1.000000\n",
      "escolari_mean           0.423626\n",
      "escolari_max            0.373091\n",
      "escolari                0.333791\n",
      "meaneduc                0.331489\n",
      "escolari_min            0.306693\n",
      "cielorazo               0.295249\n",
      "eviv3                   0.293540\n",
      "instlevel8_aggr_mean    0.293307\n",
      "epared3                 0.280947\n",
      "escolari_age_min        0.276896\n",
      "pisomoscer              0.275452\n",
      "adult_percent           0.263882\n",
      "etecho3                 0.261142\n",
      "escolari_age_mean       0.258934\n",
      "escolari_sum            0.256726\n",
      "paredblolad             0.254469\n",
      "edjefe                  0.235687\n",
      "instlevel8              0.235102\n",
      "escolari_age            0.232205\n",
      "Name: Target, dtype: float64\n",
      "**************************************************\n",
      "The most 20 negative feature: \n",
      "child_percent       -0.263882\n",
      "hogar_nin           -0.266309\n",
      "dependency_count    -0.283908\n",
      "dependency          -0.304563\n",
      "child_per_room      -0.305541\n",
      "child_per_bedroom   -0.308308\n",
      "elimbasu5                 NaN\n",
      "estadocivil1              NaN\n",
      "parentesco1               NaN\n",
      "parentesco2               NaN\n",
      "parentesco3               NaN\n",
      "parentesco4               NaN\n",
      "parentesco5               NaN\n",
      "parentesco6               NaN\n",
      "parentesco7               NaN\n",
      "parentesco8               NaN\n",
      "parentesco9               NaN\n",
      "parentesco10              NaN\n",
      "parentesco11              NaN\n",
      "parentesco12              NaN\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)\n",
    "print(f'The most 20 positive feature: \\n{correlation.head(20)}')\n",
    "print('*'*50)\n",
    "\n",
    "print(f'The most 20 negative feature: \\n{correlation.tail(20)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(predictions, truth):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "\n",
    "train.drop(columns=['Target'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#parameter value is copied from \n",
    "clf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.01, objective='multiclass',\n",
    "                             random_state=2, silent=True, metric='None', \n",
    "                             n_jobs=4, n_estimators=5000, class_weight='balanced',\n",
    "                             colsample_bytree =  0.93, min_child_samples = 95, num_leaves = 14, subsample = 0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.14541\n",
      "[200]\tvalid_0's multi_logloss: 1.06429\n",
      "[300]\tvalid_0's multi_logloss: 1.02532\n",
      "[400]\tvalid_0's multi_logloss: 1.00655\n",
      "[500]\tvalid_0's multi_logloss: 0.994713\n",
      "[600]\tvalid_0's multi_logloss: 0.986215\n",
      "[700]\tvalid_0's multi_logloss: 0.98294\n",
      "[800]\tvalid_0's multi_logloss: 0.979716\n",
      "[900]\tvalid_0's multi_logloss: 0.979418\n",
      "[1000]\tvalid_0's multi_logloss: 0.978738\n",
      "[1100]\tvalid_0's multi_logloss: 0.979874\n",
      "[1200]\tvalid_0's multi_logloss: 0.980912\n",
      "[1300]\tvalid_0's multi_logloss: 0.981514\n",
      "Early stopping, best iteration is:\n",
      "[997]\tvalid_0's multi_logloss: 0.978719\n",
      "###\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.15078\n",
      "[200]\tvalid_0's multi_logloss: 1.06904\n",
      "[300]\tvalid_0's multi_logloss: 1.02695\n",
      "[400]\tvalid_0's multi_logloss: 1.00668\n",
      "[500]\tvalid_0's multi_logloss: 0.994985\n",
      "[600]\tvalid_0's multi_logloss: 0.990188\n",
      "[700]\tvalid_0's multi_logloss: 0.986671\n",
      "[800]\tvalid_0's multi_logloss: 0.98523\n",
      "[900]\tvalid_0's multi_logloss: 0.983329\n",
      "[1000]\tvalid_0's multi_logloss: 0.982367\n",
      "[1100]\tvalid_0's multi_logloss: 0.981121\n",
      "[1200]\tvalid_0's multi_logloss: 0.981518\n",
      "[1300]\tvalid_0's multi_logloss: 0.982148\n",
      "[1400]\tvalid_0's multi_logloss: 0.984415\n",
      "Early stopping, best iteration is:\n",
      "[1084]\tvalid_0's multi_logloss: 0.980818\n",
      "###\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.14629\n",
      "[200]\tvalid_0's multi_logloss: 1.06026\n",
      "[300]\tvalid_0's multi_logloss: 1.02312\n",
      "[400]\tvalid_0's multi_logloss: 0.997959\n",
      "[500]\tvalid_0's multi_logloss: 0.980474\n",
      "[600]\tvalid_0's multi_logloss: 0.9674\n",
      "[700]\tvalid_0's multi_logloss: 0.957936\n",
      "[800]\tvalid_0's multi_logloss: 0.951838\n",
      "[900]\tvalid_0's multi_logloss: 0.945256\n",
      "[1000]\tvalid_0's multi_logloss: 0.939818\n",
      "[1100]\tvalid_0's multi_logloss: 0.933334\n",
      "[1200]\tvalid_0's multi_logloss: 0.927716\n",
      "[1300]\tvalid_0's multi_logloss: 0.924246\n",
      "[1400]\tvalid_0's multi_logloss: 0.920138\n",
      "[1500]\tvalid_0's multi_logloss: 0.917622\n",
      "[1600]\tvalid_0's multi_logloss: 0.917188\n",
      "[1700]\tvalid_0's multi_logloss: 0.918652\n",
      "[1800]\tvalid_0's multi_logloss: 0.918962\n",
      "[1900]\tvalid_0's multi_logloss: 0.919004\n",
      "Early stopping, best iteration is:\n",
      "[1530]\tvalid_0's multi_logloss: 0.916833\n",
      "###\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.148\n",
      "[200]\tvalid_0's multi_logloss: 1.06192\n",
      "[300]\tvalid_0's multi_logloss: 1.0225\n",
      "[400]\tvalid_0's multi_logloss: 1.00385\n",
      "[500]\tvalid_0's multi_logloss: 0.990743\n",
      "[600]\tvalid_0's multi_logloss: 0.981167\n",
      "[700]\tvalid_0's multi_logloss: 0.972363\n",
      "[800]\tvalid_0's multi_logloss: 0.966941\n",
      "[900]\tvalid_0's multi_logloss: 0.963503\n",
      "[1000]\tvalid_0's multi_logloss: 0.959085\n",
      "[1100]\tvalid_0's multi_logloss: 0.9578\n",
      "[1200]\tvalid_0's multi_logloss: 0.957993\n",
      "[1300]\tvalid_0's multi_logloss: 0.957911\n",
      "[1400]\tvalid_0's multi_logloss: 0.956904\n",
      "[1500]\tvalid_0's multi_logloss: 0.956784\n",
      "[1600]\tvalid_0's multi_logloss: 0.956951\n",
      "[1700]\tvalid_0's multi_logloss: 0.957458\n",
      "[1800]\tvalid_0's multi_logloss: 0.958908\n",
      "[1900]\tvalid_0's multi_logloss: 0.958812\n",
      "Early stopping, best iteration is:\n",
      "[1528]\tvalid_0's multi_logloss: 0.956196\n",
      "###\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.13937\n",
      "[200]\tvalid_0's multi_logloss: 1.05794\n",
      "[300]\tvalid_0's multi_logloss: 1.02334\n",
      "[400]\tvalid_0's multi_logloss: 1.00133\n",
      "[500]\tvalid_0's multi_logloss: 0.989759\n",
      "[600]\tvalid_0's multi_logloss: 0.983892\n",
      "[700]\tvalid_0's multi_logloss: 0.981761\n",
      "[800]\tvalid_0's multi_logloss: 0.97944\n",
      "[900]\tvalid_0's multi_logloss: 0.975564\n",
      "[1000]\tvalid_0's multi_logloss: 0.972424\n",
      "[1100]\tvalid_0's multi_logloss: 0.970499\n",
      "[1200]\tvalid_0's multi_logloss: 0.969967\n",
      "[1300]\tvalid_0's multi_logloss: 0.970202\n",
      "[1400]\tvalid_0's multi_logloss: 0.969997\n",
      "[1500]\tvalid_0's multi_logloss: 0.969055\n",
      "[1600]\tvalid_0's multi_logloss: 0.971064\n",
      "[1700]\tvalid_0's multi_logloss: 0.971457\n",
      "[1800]\tvalid_0's multi_logloss: 0.973449\n",
      "[1900]\tvalid_0's multi_logloss: 0.975499\n",
      "Early stopping, best iteration is:\n",
      "[1510]\tvalid_0's multi_logloss: 0.968785\n"
     ]
    }
   ],
   "source": [
    "kfold = 5\n",
    "kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "\n",
    "predicts_result = []\n",
    "y_val_list = []\n",
    "y_val_pred_list = []\n",
    "for train_index, test_index in kf.split(train, y):\n",
    "    print(\"###\")\n",
    "    X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric = \"logloss\", early_stopping_rounds=400, verbose=100)\n",
    "#     clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric = evaluate_macroF1_lgb, early_stopping_rounds=400, verbose=100)\n",
    "    y_val_list.append(y_val)\n",
    "    y_val_pred_list.append(clf.predict(X_val))\n",
    "    predicts_result.append(clf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a072e957c135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf1_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_pred_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mf1_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_val_list' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_list = []\n",
    "for j in range(len(y_val_list)):\n",
    "    f1 = f1_score(y_val_pred_list[j], y_val_list[j], average='macro')\n",
    "    f1_list.append(f1)\n",
    "    print(f1)\n",
    "np.array(f1_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_macroF1_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('a_k10_4_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
