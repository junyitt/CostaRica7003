{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#for installing lightgbm package to jupyter\n#import sys\n#!{sys.executable} -m pip install lightgbm","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\npd.options.display.max_columns = 150\n\n#for machine learning\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nimport lightgbm as lgb\n\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Read in data\ntrain = pd.read_csv('../input/train.csv')\ntrain.info()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\ntest.info()\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train data have 9557 entries, Test data have 23855 entries. Lets take a look at the statistic of the attributes.**"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"train.describe()\ntest.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** If we look carefully, There is an outlier for attribute rez_esc in test data.**"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"test.loc[test.loc[:,\"rez_esc\"]==99,\"rez_esc\"]\n#We can see that there is only one outlier =99, the rest of the test data is okay\n#According to answer from kaggle competition host, the value can be safely changed to 5.\n#https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403\ntest.loc[test.loc[:,\"rez_esc\"]==99,\"rez_esc\"]=5\ntest.loc[:,\"rez_esc\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we will deal with missing values in both test and train dataset. **"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#we will first check for missing values in the columns\ntrain_na= pd.DataFrame((train.isnull().sum().values),index=train.columns, columns=['isNA']).sort_values(by=['isNA'],ascending=False)\nif train_na.loc[train_na.loc[:,'isNA']>0,:].shape[0]>1 :\n    train_na.loc[train_na.loc[:,'isNA']> 0,]\n\nelse:\n    print('no NA in train set')\n\ntest_na= pd.DataFrame((test.isnull().sum().values),index=test.columns, columns=['isNA']).sort_values(by=['isNA'],ascending=False)\nif train_na.loc[train_na.loc[:,'isNA']>0,:].shape[0]>1 :\n    test_na.loc[test_na.loc[:,'isNA']> 0,]\nelse:\n    print('no NA in test set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see the missing values are largely from **\n\n****    rez_esc: years behind in school:***\n\n****    v18q1: number of tablets household owns***\n\n****    v2a1: monthly rent payment***\n\n****    meaneduc: average years of education for adults***\n\n****    SQBmeaned is the square of meaneduc***"},{"metadata":{},"cell_type":"markdown","source":"**    rez_esc: years behind in school:**\n\n    Data is only available if age of individual from 7 to 17 years old. \n    We will set 0 to all other null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"rez_esc_age=train.loc[train['rez_esc'].isnull()==False, 'age']\n\nplt.hist(x=rez_esc_age,)\nplt.xticks(np.arange(min(rez_esc_age), max(rez_esc_age)+1, 1.0),rotation = 60),\nplt.ylabel('frequence of rez_esc')\nplt.xlabel('Age')\nplt.title('Non-null rez_esc Frequency according to age')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**    v2a1: monthly rent payment**\n    \n    this depends on tipovivi2 and tipovivi3, v2a1 is NA if tipovivi2 or tipovivi3 is 0\n    tipovivi2 (a true false statement if an individual owns the house and is paying installment). \n    tipovivi3 (a true false statement if an individual is renting the house). \n    We will assume 0 for NA in v2a1"},{"metadata":{"trusted":true},"cell_type":"code","source":"tipos=[x for x in train if x.startswith('tipo')]\nrentNA_status=train.loc[train['v2a1'].isnull(), tipos].sum()\nplt.bar(tipos,rentNA_status,align='center')\nplt.xticks([0,1,2,3,4],['Owns and Paid off','Owns and Paying', 'Renting','Precarious','Other'],rotation = 60),\nplt.ylabel('Frequency')\nplt.title(\"Missing Rental 'v2a1' according to Home Ownership Status\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****    v18q1: number of tablets household owns***\n\n    This depends on v18q (a true false statement if an individual own a tablet). v18q1 is NA if v18q is 0\n    We will assume 0 for NA in v18q1"},{"metadata":{"trusted":true},"cell_type":"code","source":"Tablet_status=train.loc[train['v18q1'].isnull(), 'v18q']\nplt.hist(x=Tablet_status)\nplt.xticks([0,1,2],['Do not Own a Table','Owns a Tablet'],rotation=60),\nplt.ylabel('Frequency missing value on v18q1')\nplt.xlabel('Individual Tablet Ownership (v18q)')\nplt.title('Missing value on household tablet ownership vs individual tablet ownership')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**    meaneduc: average years of education for adults**\n    \n    We will replace this with mode\n    \n**    SQBmeaned is the square of meaneduc**\n    \n    replace with square of replaced meaneduc"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(10,5))\nplt.hist(x=train['meaneduc'],bins=int(train['meaneduc'].max()))\nplt.xticks(np.arange(min(train['meaneduc']), max(train['meaneduc'])+1),rotation=60),\nplt.ylabel('Frequency')\nplt.xlabel('average years of education for adults (18+)')\nplt.title('Histogram for meaneduc')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"train.loc[:,\"meaneduc\"].mode()\n#train: mode for meaneduc is 6 replace NA with 6, replace SQBmeaned NA to 36\ntrain.loc[train.loc[:,\"meaneduc\"].isnull()==True,\"meaneduc\"] = 6\ntrain.loc[train.loc[:,\"SQBmeaned\"].isnull()==True,\"SQBmeaned\"] = 36\n\ntest.loc[:,\"meaneduc\"].mode()\n#test: mode for meaneduc is 6 replace NA with 6, replace SQBmeaned NA to 36\ntest.loc[test.loc[:,\"meaneduc\"].isnull()==True,\"meaneduc\"] = 6\ntest.loc[test.loc[:,\"SQBmeaned\"].isnull()==True,\"SQBmeaned\"] = 36\n\n\n#Replace all NA values for remaining 3 attributes with 0no\ntrain.loc[train.loc[:,\"rez_esc\"].isnull()==True,\"rez_esc\"] = 0\ntrain.loc[train.loc[:,\"v18q1\"].isnull()==True,\"v18q1\"] = 0\ntrain.loc[train.loc[:,\"v2a1\"].isnull()==True,\"v2a1\"] = 0\n\ntest.loc[test.loc[:,\"rez_esc\"].isnull()==True,\"rez_esc\"] = 0\ntest.loc[test.loc[:,\"v18q1\"].isnull()==True,\"v18q1\"] = 0\ntest.loc[test.loc[:,\"v2a1\"].isnull()==True,\"v2a1\"] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for missing values again:\ntrain_na= pd.DataFrame((train.isnull().sum().values),index=train.columns, columns=['isNA']).sort_values(by=['isNA'],ascending=False)\nif train_na.loc[train_na.loc[:,'isNA']>0,:].shape[0]>1 :\n    train_na.loc[train_na.loc[:,'isNA']> 0,]\n\nelse:\n    print('no NA in train set')\n\ntest_na= pd.DataFrame((test.isnull().sum().values),index=test.columns, columns=['isNA']).sort_values(by=['isNA'],ascending=False)\nif train_na.loc[train_na.loc[:,'isNA']>0,:].shape[0]>1 :\n    test_na.loc[test_na.loc[:,'isNA']> 0,]\nelse:\n    print('no NA in test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Investigate if all individuals in the household have the same poverty target\ntarget_Discrepancy=(train.groupby('idhogar')['Target'].nunique()>1)\n\nprint('There are ',target_Discrepancy.sum(),'households with contradicting targets, out of 2988 households in the train dataset')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets see the data for 85 households that have discrepancy in target poverty level**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Discrepancy_Index=(train.groupby('idhogar')['Target'].transform('nunique')>1)\nHHID_Discrepancy=train.loc[Discrepancy_Index,'idhogar'].unique()\n#household with contradicting target\ntrain.loc[train['idhogar'].isin(HHID_Discrepancy),['idhogar','parentesco1','Target']].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Judging from the data, the household head target might not be necessary true. Although prediction scoring is based on household head target, we should be able to safely replace the household target using the mode target of the household.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor HH in HHID_Discrepancy:\n    Targets= (train.loc[train['idhogar']==HH,'Target'])\n\n    if Targets.mode().shape[0] >1:\n        for i in Targets.index:\n            if train.loc[i,'parentesco1']==1:\n                HeadTarget= train.loc[i,\"Target\"]    \n        for i in Targets.index:\n            train.loc[i,'Target']=HeadTarget\n    elif Targets.mode().shape[0]==1:\n        for i in Targets.index:\n            TrueTarget=int(Targets.mode())\n            train.loc[i,'Target']=TrueTarget\n        \n# Check for household targets discrepancy again for confirmation\ntarget_Discrepancy=(train.groupby('idhogar')['Target'].nunique()>1)\n\nprint('There are ',target_Discrepancy.sum(),'households with contradicting targets, out of 2988 households in the train dataset')\n\ntrain.head()\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are 9 columns where the attributes are the squared of other attributes. We do not need those in our model as the model are smart enough to detect non-linear relationship. **\n\n**Remove (SQBescolari, SQBage, SQBHogar_ttal,SQBedjefe, SQBhogar_nin,SQBovercrowding, SQBdependency, SQBMeaned, agesq)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(columns=train.columns[133:142],axis=1)\n\ntest=test.drop(columns=test.columns[133:142],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalize int and float type columns for boxplot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler=preprocessing.MinMaxScaler()\ntrainNorm= train.select_dtypes(include='int64')\ntrainNorm=pd.DataFrame(min_max_scaler.fit_transform(trainNorm))\ntrainNorm.columns=train.select_dtypes(include='int64').columns\n\n\ntestNorm= test.select_dtypes(include='int64')\ntestNorm=pd.DataFrame(min_max_scaler.fit_transform(testNorm))\ntestNorm.columns=test.select_dtypes(include='int64').columns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_boxplot = trainNorm.iloc[:,2:134].boxplot(figsize=(140,5))\n#Click on figure to expand","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test_boxplot = testNorm.iloc[:,2:134].boxplot(figsize=(140,5))\n#Click on figure to expand","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Since prediction is scored only for the household head. We need to make new features that is household level and not individual. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting new features for household specific in train data\n\n#Number of Adults not including seniors >65\ntrain['Adults']=train['hogar_adul']-train['hogar_mayor']\n#Number of children < 19yo and seniors>65\ntrain['Dependents']=train['hogar_nin']+train['hogar_mayor']\n#Number of teenager from 12 to 19\ntrain['Teenagers']=train['hogar_nin']-train['r4t1']\n#Dependency is number of dependents per adults. This replaces the original dependency data from dataset.\ntrain['dependency']=train['Dependents']/train['Adults']\n#Percentage of Adults in household\ntrain['P_Adults']=train['Adults']/train['hogar_total']\n#Percentage of Male Adults in household\ntrain['P_Adults_Male']=train['r4h3']/train['hogar_total']\n#Percentage Female Adults in household\ntrain['P_Adults_Female']=train['r4m3']/train['hogar_total']\n#Percentage Children <19yo in household\ntrain['P_Children']=train['hogar_nin']/train['hogar_total']\n#Percentage of Seniors in household\ntrain['P_Seniors']=train['hogar_mayor']/train['hogar_total']\n#Percentage of Teenagers in household\ntrain['P_Teenagers']=train['Teenagers']/train['hogar_total']\n#Rent per person in household)\ntrain['RentHH']=train['v2a1']/train['hogar_total']\n#Rent per Adult in household\ntrain['RentAdults']=train['v2a1']/train['Adults']\n#Tablet per person in household\ntrain['Tablet_PP']=train['v18q1']/train['hogar_total']\n#Mobile Phone per person in household\ntrain['Phone_PP']=train['qmobilephone']/train['hogar_total']\n#Bedroom per person in household\ntrain['Bedroom_PP']=train['bedrooms']/train['hogar_total']\n#Appliance scoring. Higher the better\ntrain['Appliances']=train['refrig']+train['computer']+train['television']\n#Household size Difference\ntrain['HHS_Diff']=train['tamviv']-train['hhsize']\n\n\n#New Scoring For Education Level\nfor i in train.index:\n    if train.loc[i,\"instlevel9\"] ==1 :\n        train.loc[i,'EduLevel']= 6\n    elif train.loc[i,\"instlevel8\"] ==1 :\n        train.loc[i,'EduLevel']= 5\n                   #higher scoring for completing tertiary education\n    elif train.loc[i,\"instlevel7\"] ==1 :\n        train.loc[i,'EduLevel']= 3                   \n    elif train.loc[i,\"instlevel5\"]==1 :\n        train.loc[i,'EduLevel']= 2\n    elif train.loc[i,[\"instlevel4\",\"instlevel3\",\"instlevel6\"]].sum() >0 :\n        train.loc[i,'EduLevel']= 1                   \n    else:\n        train.loc[i,'EduLevel']= 0\n    \n\ntrain.head()\n\n#We replicate the same for test data since we need the same features for prediction\n\ntest['Adults']=test['hogar_adul']-test['hogar_mayor']\ntest['Dependents']=test['hogar_nin']+test['hogar_mayor']\ntest['Teenagers']=test['hogar_nin']-test['r4t1']\ntest['dependency']=test['Dependents']/test['Adults']\ntest['P_Adults']=test['Adults']/test['hogar_total']\ntest['P_Adults_Male']=test['r4h3']/test['hogar_total']\ntest['P_Adults_Female']=test['r4m3']/test['hogar_total']\ntest['P_Children']=test['hogar_nin']/test['hogar_total']\ntest['P_Seniors']=test['hogar_mayor']/test['hogar_total']\ntest['P_Adultish']=test['Teenagers']/test['hogar_total']\ntest['RentHH']=test['v2a1']/test['hogar_total']\ntest['RentAdults']=test['v2a1']/test['Adults']\ntest['Tablet_PP']=test['v18q1']/test['hogar_total']\ntest['Phone_PP']=test['qmobilephone']/test['hogar_total']\ntest['Bedroom_PP']=test['bedrooms']/test['hogar_total']\ntest['Appliances']=test['refrig']+test['computer']+test['television']\ntest['HHS_Diff']=test['tamviv']-test['hhsize']\n\n#New Scoring For Education Level\nfor i in test.index:\n    if test.loc[i,\"instlevel9\"] ==1 :\n        test.loc[i,'EduLevel']= 6\n    elif test.loc[i,\"instlevel8\"] ==1 :\n        test.loc[i,'EduLevel']= 5\n                   #higher scoring for completing tertiary education\n    elif test.loc[i,\"instlevel7\"] ==1 :\n        test.loc[i,'EduLevel']= 3                   \n    elif test.loc[i,\"instlevel5\"]==1 :\n        test.loc[i,'EduLevel']= 2\n    elif test.loc[i,[\"instlevel4\",\"instlevel3\",\"instlevel6\"]].sum() >0 :\n        test.loc[i,'EduLevel']= 1                   \n    else:\n        test.loc[i,'EduLevel']= 0\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we want to aggregate existing features to be representable in household level**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"List_Mean = ['rez_esc', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5',\n             'estadocivil6', 'estadocivil7', 'parentesco2','parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7',\n             'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12','instlevel1', 'instlevel2', 'instlevel3',\n             'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9','overcrowding']\n\nList_Summary = ['age', 'escolari','dis','EduLevel']\n\n\ntrainGP = pd.DataFrame()\ntestGP = pd.DataFrame()\n\nfor item in List_Mean:\n    group_train_mean = train[item].groupby(train['idhogar']).mean()\n    group_test_mean = test[item].groupby(test['idhogar']).mean()\n    new_col = item + '_mean'\n    trainGP[new_col] = group_train_mean\n    testGP[new_col] = group_test_mean\n\nfor item in List_Summary:\n    for function in ['mean','std','min','max','sum']:\n        group_train = train[item].groupby(train['idhogar']).agg(function)\n        group_test = test[item].groupby(test['idhogar']).agg(function)\n        new_col = item + '_' + function\n        trainGP[new_col] = group_train\n        testGP[new_col] = group_test\n        \n#adding one final feature\n        \ntrainGP['age_extreme']=trainGP['age_max']-trainGP['age_min']\ntestGP['age_extreme']=testGP['age_max']-testGP['age_min']\ntrainGP['escolari_extreme']=trainGP['escolari_max']-trainGP['escolari_min']\ntestGP['escolari_extreme']=testGP['escolari_max']-testGP['escolari_min']\n        \ntrainGP.head()\ntestGP.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we want to merge the new feature together with the aggregated features of household"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainGP = trainGP.reset_index()\ntestGP = testGP.reset_index()\n\ntrainML = pd.merge(train, trainGP, on='idhogar')\ntestML = pd.merge(test, testGP, on='idhogar')\n\n#fill all na as 0\ntrainML.fillna(value=0, inplace=True)\ntestML.fillna(value=0, inplace=True)\n\ntrainML.head()\ntestML.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = testML[['Id']]\n#remove features that are not relevant to reduce size\ntrainML.drop(columns=['idhogar','Id','tamhog','r4t3','hhsize','hogar_adul','edjefe','edjefa'],inplace=True)\ntestML.drop(columns=['idhogar','Id','tamhog','r4t3','hhsize','hogar_adul','edjefe','edjefa'],inplace=True)\n\ncorrelation=trainML.corr()\ncorrelation = correlation ['Target'].sort_values(ascending=False)\nprint(f'The most 20 positive feature: \\n{correlation.head(20)}')\nprint('*'*50)\n\nprint(f'The most 20 negative feature: \\n{correlation.tail(20)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the train and test data finally preprocessed. We will make use of the Light GBM model and parameters adjusted from MIsha Lisovyi.https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro"},{"metadata":{"trusted":true},"cell_type":"code","source":"y= trainML['Target']\ntrainML.drop(columns=['Target'], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameter value is copied\nclf = lgb.LGBMClassifier(max_depth=8, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='multi_logloss', \n                             n_jobs=4, n_estimators=5000, class_weight='balanced',\n                             colsample_bytree =  0.93, min_child_samples = 95, num_leaves = 80, subsample = 0.96)\n\n\nclf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = 5\nkf = StratifiedKFold(n_splits=kfold, shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#QuickCheck to makesure train and test have have same columns size\ntrainML.shape\ntestML.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts_result = []\nfor trainML_index, testML_index in kf.split(trainML, y):\n    print(\"###\")\n    X_train, X_val = trainML.iloc[trainML_index], trainML.iloc[testML_index]\n    y_train, y_val = y.iloc[trainML_index], y.iloc[testML_index]\n    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n            early_stopping_rounds=400, verbose=100)\n    predicts_result.append(clf.predict(testML))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"indices = np.argsort(clf.feature_importances_)[::-1]\nindices = indices[:75]\n\n# Visualise these with a barplot\nplt.subplots(figsize=(20, 15))\ng = sns.barplot(y=trainML.columns[indices], x = clf.feature_importances_[indices], orient='h')\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=12)\ng.tick_params(labelsize=9)\ng.set_title(\"LightGBM feature importance\");","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission.to_csv('SubmissionV5_15May2019.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}