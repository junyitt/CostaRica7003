{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df.head()\n",
    "\n",
    "#impute v2a1 (Monthly rent payment) with mean\n",
    "df[\"v2a1\"] = df[\"v2a1\"].fillna(df[\"v2a1\"].mean())\n",
    "\n",
    "#impute v18q1 (number of tablets household owns) with 0\n",
    "df[\"v18q1\"] = df[\"v18q1\"].fillna(0)\n",
    "\n",
    "#remove rez_esc column (Years behind in school)\n",
    "df = df.drop(columns=\"rez_esc\", index = 1)\n",
    "\n",
    "#remove 5 rows with NA \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove ID Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ID\n",
    "df = df.drop([\"Id\", \"idhogar\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Inconsistent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#replace yes with 1, replace no with 0\n",
    "df[[\"edjefe\", \"edjefa\"]] = df[[\"edjefe\", \"edjefa\"]].apply(lambda x: x.replace(\"no\", 0).replace(\"yes\", 1))\n",
    "\n",
    "#convert string to numeric\n",
    "df[\"edjefe\"] = pd.to_numeric(df[\"edjefe\"])\n",
    "df[\"edjefa\"] = pd.to_numeric(df[\"edjefa\"])\n",
    "\n",
    "#create a new column called head_edu (head of household years of education), remove the two columns\n",
    "df[\"head_edu\"] = df[[\"edjefe\", \"edjefa\"]].max(axis = 1) \n",
    "df = df.drop([\"edjefe\", \"edjefa\"], axis = 1)\n",
    "\n",
    "#Add dependency_rate column\n",
    "df[\"dependency_rate\"] = (df[\"hogar_mayor\"] + df[\"hogar_nin\"]) / df[\"hogar_total\"] \n",
    "#Remove dependency column\n",
    "df = df.drop(\"dependency\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "### Binning - age, v2a1 (monthly rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gender - Reduce to 1 column** (avoid multicollinearity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"] = df[\"male\"] #if male then 1, else 0\n",
    "df = df.drop([\"male\", \"female\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predominant material on the outside wall** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']\n",
      "Removed 'paredother'.\n"
     ]
    }
   ],
   "source": [
    "wall_columns = list(df.filter(regex='^pared').columns)\n",
    "print(wall_columns)\n",
    "if (df[wall_columns].sum(axis = 1) == 1).all(): #check if sum of the 8 columns is 1 for all rows\n",
    "    df = df.drop([\"paredother\"], axis = 1) #if yes, then remove 1 column. In this case, remove 'paredother'\n",
    "    print(\"Removed 'paredother'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predominant material on the floor** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']\n",
      "Removed 'pisoother'.\n"
     ]
    }
   ],
   "source": [
    "floor_columns = list(df.filter(regex='^piso').columns)\n",
    "print(floor_columns)\n",
    "if (df[floor_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"pisoother\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'pisoother'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predominant material on the roof** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['techozinc', 'techoentrepiso', 'techocane', 'techootro']\n",
      "       techozinc  techoentrepiso  techocane  techootro  cielorazo\n",
      "count       66.0            66.0       66.0       66.0       66.0\n",
      "mean         0.0             0.0        0.0        0.0        0.0\n",
      "std          0.0             0.0        0.0        0.0        0.0\n",
      "min          0.0             0.0        0.0        0.0        0.0\n",
      "25%          0.0             0.0        0.0        0.0        0.0\n",
      "50%          0.0             0.0        0.0        0.0        0.0\n",
      "75%          0.0             0.0        0.0        0.0        0.0\n",
      "max          0.0             0.0        0.0        0.0        0.0\n",
      "         techozinc  techoentrepiso    techocane    techootro    cielorazo\n",
      "count  9485.000000     9485.000000  9485.000000  9485.000000  9485.000000\n",
      "mean      0.976805        0.017818     0.003163     0.002214     0.681919\n",
      "std       0.150529        0.132295     0.056154     0.047004     0.465756\n",
      "min       0.000000        0.000000     0.000000     0.000000     0.000000\n",
      "25%       1.000000        0.000000     0.000000     0.000000     0.000000\n",
      "50%       1.000000        0.000000     0.000000     0.000000     1.000000\n",
      "75%       1.000000        0.000000     0.000000     0.000000     1.000000\n",
      "max       1.000000        1.000000     1.000000     1.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "roof_columns = list(df.filter(regex='^techo').columns) \n",
    "print(roof_columns)\n",
    "print(df[df[roof_columns].sum(axis = 1) == 0][roof_columns + [\"cielorazo\"]].describe()) \n",
    "print(df[df[roof_columns].sum(axis = 1) == 1][roof_columns + [\"cielorazo\"]].describe()) \n",
    "#This shows that if the 4 columns (techo*) are all 0, then 'cielorazo'is 0.\n",
    "#However, there are cases where any of the 4 columns with 1, does not imply 'cielorazo' is 1. \n",
    "#(e.g. There are cases where the roof is zink, but the house has no ceiling)\n",
    "#Therefore, we cannot remove any of the 4 columns and 'cielorazo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Water provision** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abastaguadentro', 'abastaguafuera', 'abastaguano']\n",
      "Removed 'abastaguano'.\n"
     ]
    }
   ],
   "source": [
    "water_columns = list(df.filter(regex='^abastagua').columns)\n",
    "print(water_columns)\n",
    "if (df[water_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"abastaguano\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'abastaguano'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Electricity** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['public', 'planpri', 'noelec', 'coopele']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_columns = [\"public\", \"planpri\", \"noelec\", \"coopele\"]\n",
    "print(electricity_columns)\n",
    "(df[electricity_columns].sum(axis = 1) == 1).all() #check if sum of the relevant columns is 1 for all rows\n",
    "# Does not require removing any column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toilet** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']\n",
      "Removed 'sanitario6'.\n"
     ]
    }
   ],
   "source": [
    "toilet_columns = list(df.filter(regex='^sanitario').columns)\n",
    "print(toilet_columns)\n",
    "if (df[toilet_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"sanitario6\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'sanitario6'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main source of energy** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']\n",
      "Removed 'energcocinar1'.\n"
     ]
    }
   ],
   "source": [
    "energy_columns = list(df.filter(regex='^energcocinar').columns)\n",
    "print(energy_columns)\n",
    "if (df[energy_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"energcocinar1\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'energcocinar1'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rubbish disposal** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']\n",
      "Removed 'elimbasu6'.\n"
     ]
    }
   ],
   "source": [
    "rubbish_columns = list(df.filter(regex='^elimbasu').columns)\n",
    "print(rubbish_columns)\n",
    "if (df[rubbish_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"elimbasu6\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'elimbasu6'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Walls condition** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epared1', 'epared2', 'epared3']\n",
      "Removed 'epared2'.\n"
     ]
    }
   ],
   "source": [
    "wallc_columns = list(df.filter(regex='^epared').columns)\n",
    "print(wallc_columns)\n",
    "if (df[wallc_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"epared2\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'epared2'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Roof condition** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etecho1', 'etecho2', 'etecho3']\n",
      "Removed 'etecho2'.\n"
     ]
    }
   ],
   "source": [
    "roofc_columns = list(df.filter(regex='^etecho').columns)\n",
    "print(roofc_columns)\n",
    "if (df[roofc_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"etecho2\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'etecho2'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Floor condition** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eviv1', 'eviv2', 'eviv3']\n",
      "Removed 'eviv2'.\n"
     ]
    }
   ],
   "source": [
    "floorc_columns = list(df.filter(regex='^eviv').columns)\n",
    "print(floorc_columns)\n",
    "if (df[floorc_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"eviv2\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'eviv2'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Civil Status** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7']\n",
      "Removed 'estadocivil7'.\n"
     ]
    }
   ],
   "source": [
    "civil_columns = list(df.filter(regex='^estadocivil').columns)\n",
    "print(civil_columns)\n",
    "if (df[civil_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"estadocivil7\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'estadocivil7'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Household Status** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parentesco1', 'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12']\n",
      "Removed 'parentesco12'.\n"
     ]
    }
   ],
   "source": [
    "household_columns = list(df.filter(regex='^parentesco').columns)\n",
    "print(household_columns)\n",
    "if (df[household_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"parentesco12\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'parentesco12'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Education Level** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']\n",
      "count    9551.000000\n",
      "mean        0.999686\n",
      "std         0.017721\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "edulevel_columns = list(df.filter(regex='^instlevel').columns)\n",
    "print(edulevel_columns)\n",
    "if (df[edulevel_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"instlevel9\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'instlevel9'.\")\n",
    "else:\n",
    "    print(df[edulevel_columns].sum(axis = 1).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**House ownership** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5']\n",
      "Removed 'tipovivi5'.\n"
     ]
    }
   ],
   "source": [
    "houseown_columns = list(df.filter(regex='^tipovivi').columns)\n",
    "print(houseown_columns)\n",
    "if (df[houseown_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"tipovivi5\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'tipovivi5'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Region** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']\n",
      "Removed 'lugar6'.\n"
     ]
    }
   ],
   "source": [
    "region_columns = list(df.filter(regex='^lugar').columns)\n",
    "print(region_columns)\n",
    "if (df[region_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"lugar6\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'lugar6'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Settlement** (avoid multicollinearity by removing 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['area1', 'area2']\n",
      "Removed 'area2'.\n"
     ]
    }
   ],
   "source": [
    "settlement_columns = list(df.filter(regex='^area').columns)\n",
    "print(settlement_columns)\n",
    "if (df[settlement_columns].sum(axis = 1) == 1).all(): #check if sum of the relevant columns is 1 for all rows\n",
    "    df = df.drop([\"area2\"], axis = 1) #if yes, then remove 1 column. \n",
    "    print(\"Removed 'area2'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hhsize, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tamhog, tamviv\n",
    "# include: r4h1, r4h2, r4m1, r4m2, tamhog\n",
    "# remove: hhsize, r4h3, r4m3, r4t1, r4t2, r4t3, tamviv\n",
    "df = df.drop([\"hhsize\", \"r4h3\", \"r4m3\", \"r4t1\", \"r4t2\", \"r4t3\", \"tamviv\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dependency_rate were calculated previously, include only hogar_nin\n",
    "## remove hogar_adul, hogar_mayor, hogar_total\n",
    "df = df.drop([\"hogar_adul\", \"hogar_mayor\", \"hogar_total\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove mobilephone (implied by qmobilephone)\n",
    "df = df.drop([\"mobilephone\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove square columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are square of another column\n",
    "square_columns = list(df.filter(like='SQ').columns) + [\"agesq\"]\n",
    "df = df.drop(square_columns, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = pd.isna(df).sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(df[[\"v2a1\"]].iloc[0:int(0.6*df.shape[0])])\n",
    "df[\"v2a1\"] = scaler.transform(df[[\"v2a1\"]])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3152,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"Target\"], axis = 1).values\n",
    "y = df[\"Target\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, ..., 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"data/test.csv\")\n",
    "df2b = clean_test(df2)\n",
    "X_TEST = df2b.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TEST = model.predict(X_TEST)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = y_TEST\n",
    "df_submission.to_csv(\"xgboost_01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00765941 0.00111498 0.001395   0.00044321 0.         0.\n",
      " 0.04585591 0.02903457 0.00597071 0.00114061 0.01327236 0.00102483\n",
      " 0.00146452 0.02719572 0.03833558 0.         0.         0.\n",
      " 0.00359541 0.         0.         0.05952775 0.01789043 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05573803 0.00025185 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00082631 0.\n",
      " 0.         0.         0.00105058 0.         0.00073098 0.\n",
      " 0.         0.01061954 0.0692902  0.         0.01268923 0.01688073\n",
      " 0.02955059 0.         0.00127465 0.         0.00221753 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.10572265 0.17154526 0.00189987 0.         0.\n",
      " 0.         0.         0.         0.         0.02450224 0.00128632\n",
      " 0.         0.03666014 0.         0.00133819 0.         0.\n",
      " 0.01141441 0.00173121 0.01082786 0.00434574 0.         0.\n",
      " 0.         0.         0.         0.00155515 0.05903736 0.11209236\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00765941 0.00111498 0.001395   0.00044321 0.         0.\n",
      " 0.04585591 0.02903457 0.00597071 0.00114061 0.01327236 0.00102483\n",
      " 0.00146452 0.02719572 0.03833558 0.         0.         0.\n",
      " 0.00359541 0.         0.         0.05952775 0.01789043 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05573803 0.00025185 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00082631 0.\n",
      " 0.         0.         0.00105058 0.         0.00073098 0.\n",
      " 0.         0.01061954 0.0692902  0.         0.01268923 0.01688073\n",
      " 0.02955059 0.         0.00127465 0.         0.00221753 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.10572265 0.17154526 0.00189987 0.         0.\n",
      " 0.         0.         0.         0.         0.02450224 0.00128632\n",
      " 0.         0.03666014 0.         0.00133819 0.         0.\n",
      " 0.01141441 0.00173121 0.01082786 0.00434574 0.         0.\n",
      " 0.         0.         0.         0.00155515 0.05903736 0.11209236\n",
      " 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 4], dtype=int64), array([   85, 23771], dtype=int64))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.feature_importances_)\n",
    "y_TEST_rf = clf.predict(X_TEST)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = y_TEST_rf\n",
    "df_submission.to_csv(\"rf_01.csv\", index=False)\n",
    "unique, counts = np.unique(y_TEST_rf, return_counts=True)\n",
    "unique, counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  143,  2698,    51, 20964], dtype=int64))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# print(clf.feature_importances_)\n",
    "y_TEST_rf = clf.predict(X_TEST)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = y_TEST_rf\n",
    "df_submission.to_csv(\"rf_02.csv\", index=False)\n",
    "unique, counts = np.unique(y_TEST_rf, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  435,  3303,   358, 19760], dtype=int64))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=250, max_depth=25, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# print(clf.feature_importances_)\n",
    "y_TEST_rf = clf.predict(X_TEST)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = y_TEST_rf\n",
    "df_submission.to_csv(\"rf_03.csv\", index=False)\n",
    "unique, counts = np.unique(y_TEST_rf, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  796,  3395,   278, 19387], dtype=int64))"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "Y_TEST_XGB = model.predict(X_TEST)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = Y_TEST_XGB\n",
    "df_submission.to_csv(\"xgb_01.csv\", index=False)\n",
    "unique, counts = np.unique(Y_TEST_XGB, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use feature importance + Use full X Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[:,model.feature_importances_ > 0.01]\n",
    "Y2 = y\n",
    "XTEST2 = X_TEST[:,model.feature_importances_ > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  594,  3689,   379, 19194], dtype=int64))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X2, Y2)\n",
    "Y_TEST_XGB = xgb.predict(XTEST2)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = Y_TEST_XGB\n",
    "df_submission.to_csv(\"xgb_02.csv\", index=False)\n",
    "unique, counts = np.unique(Y_TEST_XGB, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23856, 23)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = X[:,model.feature_importances_ > 0.012]\n",
    "Y2 = y\n",
    "XTEST2 = X_TEST[:,model.feature_importances_ > 0.012]\n",
    "XTEST2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  698,  3668,   340, 19150], dtype=int64))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X2, Y2)\n",
    "Y_TEST_XGB = xgb.predict(XTEST2)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = Y_TEST_XGB\n",
    "df_submission.to_csv(\"xgb_03.csv\", index=False)\n",
    "unique, counts = np.unique(Y_TEST_XGB, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use more features (don't remove multicollinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df2 = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = clean_test_2(df)\n",
    "cdf2 = clean_test_2(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cdf.drop([\"Target\"], axis = 1).values\n",
    "y = cdf[\"Target\"].values\n",
    "X_TEST = cdf2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  614,  3616,   328, 19298], dtype=int64))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "Y_TEST_XGB = model.predict(X_TEST)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = Y_TEST_XGB\n",
    "df_submission.to_csv(\"xgb_04.csv\", index=False)\n",
    "unique, counts = np.unique(Y_TEST_XGB, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23856, 35)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = X[:,model.feature_importances_ > 0.010]\n",
    "Y2 = y\n",
    "XTEST2 = X_TEST[:,model.feature_importances_ > 0.010]\n",
    "XTEST2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4], dtype=int64),\n",
       " array([  613,  3740,   340, 19163], dtype=int64))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X2, Y2)\n",
    "Y_TEST_XGB = xgb.predict(XTEST2)\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission[\"Target\"] = Y_TEST_XGB\n",
    "df_submission.to_csv(\"xgb_05.csv\", index=False)\n",
    "unique, counts = np.unique(Y_TEST_XGB, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
